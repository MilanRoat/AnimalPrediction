{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the paths for the directories\n",
    "base_dir = 'C:\\\\Users\\\\hp\\\\Contacts\\\\pythonProject\\\\input_datasets\\\\animals\\\\animals'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_batch(base_dir, batch_size, start_idx):\n",
    "    data = []\n",
    "    labels_type = []\n",
    "    labels_name = []\n",
    "\n",
    "    animal_types = ['herbivorous', 'carnivorous']\n",
    "    animal_type_map = {animal_type: idx for idx, animal_type in enumerate(animal_types)}\n",
    "\n",
    "    herbivores = [\n",
    "        'antelope', 'bison', 'butterfly', 'cow', 'deer', 'donkey', 'elephant',\n",
    "        'flamingo', 'goat', 'gorilla', 'grasshopper', 'hare', 'hippopotamus',\n",
    "        'horse', 'kangaroo', 'koala', 'ladybugs', 'moth', 'mouse', 'okapi',\n",
    "        'ox', 'panda', 'parrot', 'pig', 'porcupine', 'possum', 'rabbit', 'rat',\n",
    "        'reindeer', 'rhinoceros', 'sandpiper', 'sheep', 'squirrel', 'swan',\n",
    "        'turtle', 'wombat', 'zebra'\n",
    "    ]\n",
    "\n",
    "    carnivores = [\n",
    "        'badger', 'bat', 'bear', 'cat', 'chimpanzee', 'coyote', 'crab', 'crow',\n",
    "        'dog', 'dolphin', 'eagle', 'fox', 'goldfish', 'hyena', 'leopard', 'lion',\n",
    "        'lobster', 'octopus', 'orangutan', 'otter', 'owl', 'shark', 'snake', 'sparrow',\n",
    "        'squid', 'starfish', 'tiger', 'whale', 'wolf', 'woodpecker'\n",
    "    ]\n",
    "\n",
    "    animal_names = herbivores + carnivores\n",
    "    animal_name_map = {animal_name: idx for idx, animal_name in enumerate(animal_names)}\n",
    "\n",
    "    all_images = []\n",
    "\n",
    "    for animal_type in animal_types:\n",
    "        type_path = os.path.join(base_dir, animal_type)\n",
    "        for animal_name in os.listdir(type_path):\n",
    "            animal_path = os.path.join(type_path, animal_name)\n",
    "            for img_file in os.listdir(animal_path):\n",
    "                img_path = os.path.join(animal_path, img_file)\n",
    "                all_images.append((img_path, animal_type, animal_name))\n",
    "\n",
    "    batch_images = all_images[start_idx:start_idx + batch_size]\n",
    "\n",
    "    for img_path, animal_type, animal_name in batch_images:\n",
    "        img = load_img(img_path, target_size=(150, 150))\n",
    "        img_array = img_to_array(img)\n",
    "        data.append(img_array)\n",
    "        labels_type.append(animal_type_map[animal_type])\n",
    "        labels_name.append(animal_name_map[animal_name])\n",
    "\n",
    "    data = np.array(data, dtype=\"float32\") / 255.0\n",
    "    labels_type = np.array(labels_type)\n",
    "    labels_name = np.array(labels_name)\n",
    "\n",
    "    return data, labels_type, labels_name\n",
    "\n",
    "def get_total_images(base_dir):\n",
    "    total_images = 0\n",
    "    for animal_type in ['herbivorous', 'carnivorous']:\n",
    "        type_path = os.path.join(base_dir, animal_type)\n",
    "        for animal_name in os.listdir(type_path):\n",
    "            animal_path = os.path.join(type_path, animal_name)\n",
    "            total_images += len(os.listdir(animal_path))\n",
    "    return total_images\n",
    "\n",
    "total_images = get_total_images(base_dir)\n",
    "batch_size = 256  # Adjust batch size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_types = ['herbivorous', 'carnivorous']\n",
    "herbivores = [\n",
    "     'butterfly','chiken' ,'cow',  'elephant',\n",
    "    'horse', 'sheep', 'squirrel'\n",
    "    ]\n",
    "\n",
    "carnivores = [\n",
    "    'cat', 'dog', 'spider'\n",
    "    ]\n",
    "\n",
    "animal_names = herbivores + carnivores\n",
    "input_shape = (150, 150, 3)\n",
    "num_animal_types = len(animal_types)\n",
    "num_animal_names = len(animal_names)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "type_output = Dense(num_animal_types, activation='softmax', name='animal_type')(x)\n",
    "name_output = Dense(num_animal_names, activation='softmax', name='animal_name')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[type_output, name_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'animal_type': 'sparse_categorical_crossentropy',\n",
    "        'animal_name': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'animal_type': 'accuracy',\n",
    "        'animal_name': 'accuracy'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:50,  6.94s/it, loss=4.88, animal_type_loss=0.668, animal_name_loss=4.22, animal_type_acc=1, animal_name_acc=0]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:31,  5.75s/it, loss=4.91, animal_type_loss=0.694, animal_name_loss=4.21, animal_type_acc=0, animal_name_acc=0]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:32,  5.76s/it, loss=4.9, animal_type_loss=0.695, animal_name_loss=4.21, animal_type_acc=0, animal_name_acc=0]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:33,  5.87s/it, loss=4.9, animal_type_loss=0.696, animal_name_loss=4.21, animal_type_acc=0, animal_name_acc=0]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:35,  5.97s/it, loss=4.9, animal_type_loss=0.697, animal_name_loss=4.2, animal_type_acc=0, animal_name_acc=0]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:36,  6.03s/it, loss=4.9, animal_type_loss=0.698, animal_name_loss=4.2, animal_type_acc=0, animal_name_acc=0]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:38,  6.16s/it, loss=4.9, animal_type_loss=0.699, animal_name_loss=4.2, animal_type_acc=0, animal_name_acc=0.05]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:35,  5.97s/it, loss=4.89, animal_type_loss=0.696, animal_name_loss=4.19, animal_type_acc=0, animal_name_acc=0.45]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:35,  5.99s/it, loss=4.89, animal_type_loss=0.688, animal_name_loss=4.2, animal_type_acc=0.942, animal_name_acc=0.0417]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [09:46, 36.65s/it, loss=4.88, animal_type_loss=0.693, animal_name_loss=4.19, animal_type_acc=0.392, animal_name_acc=0.517]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:33,  5.81s/it, loss=4.88, animal_type_loss=0.695, animal_name_loss=4.18, animal_type_acc=0.05, animal_name_acc=0.508]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:32,  5.81s/it, loss=4.83, animal_type_loss=0.644, animal_name_loss=4.19, animal_type_acc=1, animal_name_acc=0.0167]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:33,  5.86s/it, loss=4.88, animal_type_loss=0.698, animal_name_loss=4.18, animal_type_acc=0, animal_name_acc=0.492]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:32,  5.77s/it, loss=4.87, animal_type_loss=0.698, animal_name_loss=4.18, animal_type_acc=0, animal_name_acc=0.525]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:31,  5.72s/it, loss=4.87, animal_type_loss=0.699, animal_name_loss=4.17, animal_type_acc=0, animal_name_acc=0.533]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:30,  5.64s/it, loss=4.87, animal_type_loss=0.7, animal_name_loss=4.17, animal_type_acc=0, animal_name_acc=0.575]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:29,  5.62s/it, loss=4.87, animal_type_loss=0.701, animal_name_loss=4.17, animal_type_acc=0, animal_name_acc=0.592]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 16it [01:42,  6.42s/it, loss=4.86, animal_type_loss=0.7, animal_name_loss=4.16, animal_type_acc=0.05, animal_name_acc=0.533]                           \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 18\n",
    "batch_size = 256\n",
    "total_images = get_total_images(base_dir)\n",
    "steps_per_epoch = total_images // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    progress_bar = tqdm(total=steps_per_epoch, desc=\"Training\")\n",
    "\n",
    "    for start_idx in range(0, total_images, batch_size):\n",
    "        data_batch, labels_type_batch, labels_name_batch = load_data_batch(base_dir, batch_size, start_idx)\n",
    "        loss = model.train_on_batch(data_batch, {'animal_type': labels_type_batch, 'animal_name': labels_name_batch})\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss[0],\n",
    "            'animal_type_loss': loss[1],\n",
    "            'animal_name_loss': loss[2],\n",
    "            'animal_type_acc': loss[3],\n",
    "            'animal_name_acc': loss[4]\n",
    "        })\n",
    "    \n",
    "    progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('animals (1).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_and_preprocess_image(img_path, target_size=(150, 150)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Rescale\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_animal(model, img_path, animal_name_map, animal_type_map):\n",
    "    # Load and preprocess the image\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    type_prediction = np.argmax(predictions[0], axis=1)[0]\n",
    "    name_prediction = np.argmax(predictions[1], axis=1)[0]\n",
    "\n",
    "    # Map predictions to labels\n",
    "    inv_animal_type_map = {v: k for k, v in animal_type_map.items()}\n",
    "    inv_animal_name_map = {v: k for k, v in animal_name_map.items()}\n",
    "\n",
    "    predicted_type = inv_animal_type_map[type_prediction]\n",
    "    predicted_name = inv_animal_name_map[name_prediction]\n",
    "\n",
    "    return predicted_type, predicted_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
